{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### По стандарту импортируем все необходимые модули и библиотки для решения задачи Seq2Seq для задачи машинного перевода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIEGXF8oM9tt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Постановка задачи:\n",
    "----\n",
    "\n",
    "Задача - научить RNNs  переводить предложения с одного языка на другой язык. Корпус текстовых данных лежит в директории ./data/\n",
    "Пока нам понадобиться только файл eng-rus.txt для того чтобы научить модель переводить с EN на RU язык.\n",
    "Структура файла - обычный текстовой файл, состоящий из строк, где каждая строка 1 предложение на исходном языке (EN) Затем знак табуляции \\t и предложение на целевом языке и так несколько строк в файле.\n",
    "Нам необходимо сформировать искусственно класс словаря, провести кодировку последовательности и сформировать датасет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Подготовим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyNnJyruM9t1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Определим по умолчанию 2 токена которые будут нам информировать о начале предложения и конце предложения (SOS и EOS):\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# Создадим объект словаря нашего языка, который будет хранить данные по маппингу слов - index2word и обратно word2index и плюс второстепенные методы по добавлению токена и обработке предложений:\n",
    "class LanguageVocabulary(object):\n",
    "    def __init__(self, name):\n",
    "        # название языка\n",
    "        self.name = name\n",
    "        # словарик word2index который хранит соответственно кодировку слова в целочисленный индекс словаря\n",
    "        self.word2index = {}\n",
    "        # обычный словарик который хранит распределение слов, сколько слов мы использовали и сколько обнаружили\n",
    "        self.word2count = {}\n",
    "        # Обратный словарик словарю word2index где хранятся уже индексы и замаппенные слова к каждому индексу, нужен будет для расшифровки последовательности\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        # Count SOS and EOS, храним просто общее количество слов в нашем словаре, то есть количество токенов в сформированном словарике нашего языка\n",
    "        self.n_words = 2\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "        Метод класса, для добавления предложения в словарь.\n",
    "        Каждое предложение поступающее к нам, будет разбираться на\n",
    "        примитивные токены и добавляться в словарь при помощи метода класса addword()\n",
    "        \"\"\"\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # проверяем не входит ли наше слово в словарь word2index\n",
    "        if word not in self.word2index:\n",
    "            # добавляем в качестве ключа слово а в качестве значения последнее n_words\n",
    "            self.word2index[word] = self.n_words\n",
    "            # меняем на единичку\n",
    "            self.word2count[word] = 1\n",
    "            # и соответственно меняем и index2word словарик добавляя уже слово для декодирования\n",
    "            self.index2word[self.n_words] = word\n",
    "            # инкрементируем n_words\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            # Если такое уже слово есть просто добавляем 1 что добавилось одно слово\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Класс словарика построили, теперь надо подумать как обработать последовательность текста. Создадим 2 фукнции uncode_to_ascii() и normalize_string(). Как мы помним из специфики работы Python, питоновский интерпретатор представляет строку в виде юникод кодировки, что неудобно. Необходимо перевести все в кодировку стандарта ASCII (FYI для разных языков, разный подход, прежде чем приступать к раскодировке из одного языка в другой, поищите информацию о представлении языка в памяти компьютера, например для Китайского, Японского, Иврита, Арабского и прочих языков есть своя определенная специфика). Обычно все насущные вопросы уже кем-то были решены и все решается просто поиском ответа на stackoverflow как я и сделал ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXKs8j4bM9t6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    # Декодируем из юникода в ascii\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    # Что означает данное регулярное выражение - точку, !, ? меняем на пробел чтобы этот символ стоял отдельно от всех\n",
    "    # https://docs.python.org/3/library/re.html - стандартная (родная) библиотка Python которая нужна для работы с регулярными выражениями\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # оставляем только наборы символов указанных в паттерне регулярного выражения остальное заменим на пробел\n",
    "    s = re.sub(r\"[^a-zA-Zа-яА-Я.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Создадим функцию которая будет просто открывать наши документы корпуса и создавать словарик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = open('./data/eng-rus.txt', mode='r', encoding='UTF8')\n",
    "file_out = open('./data/cleaned_eng-rus.txt', mode='w', encoding='UTF8')\n",
    "condition = True\n",
    "\n",
    "while condition:\n",
    "    line = file_in.readline()\n",
    "    data = re.sub('CC-BY.*?\\n', '', line).strip()\n",
    "    data += '\\n'\n",
    "    file_out.write(data)\n",
    "    if line == '':\n",
    "        condition = False\n",
    "\n",
    "\n",
    "file_in.close()\n",
    "file_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8T4VxZeM9t-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_languages(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    # Берем документ корпуса, лежащий в директории ./data/___.txt подставляя значения указанных языков в нашем случае eng-fra, он читается бьется на предложения\n",
    "    # lines = open('./data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    with open('./data/cleaned_%s-%s.txt' % (lang1, lang2), mode='r', encoding='UTF8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        lines = lines[:-2]\n",
    "\n",
    "    # Разбиваем построчно и нормализуем строку:\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    # Можем создавать и проходить как с целевого языка на исходный так и наоборот:\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = LanguageVocabulary(lang2)\n",
    "        output_lang = LanguageVocabulary(lang1)\n",
    "    else:\n",
    "        input_lang = LanguageVocabulary(lang1)\n",
    "        output_lang = LanguageVocabulary(lang2)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Чтобы немного упростить задачу и соответственно время на ее решение, для упрощения мы просто возьмем и отберем часть предложений которые будут начинаться на биграммы указанные в eng_prefixes и соответсвенно ограничим длину предложения документа 10-ю символами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBOwgEBdM9uB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Создадим функцию которая будет возвращать нам уже данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "6dZOGjd5M9uE",
    "outputId": "0cdd3a7f-2ac8-4872-8a81-6101d0bdd0a9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_languages(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496059 sentence pairs\n",
      "Trimmed to 28719 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 10177\n",
      "eng 4303\n",
      "['боюсь твои план не сработает .', 'i m afraid your plan won t work .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('eng', 'rus', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgtWqznCM9uH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Построим  Encoder\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9vm9QBWM9uI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Как помним hidden_size - размер скрытого состояния\n",
    "        self.hidden_size = hidden_size\n",
    "        # Слой Эмбеддингов, который из входного вектора последовательности (либо батча) отдаст представление последовательности для скрытого состояния\n",
    "        # FYI: в качестве Input_size у нас размер словаря\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # И соответственно рекуррентная ячейка GRU которая принимает MxM (hidden на hidden)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Приводим эмбеддинг к формату одного предлоежния 1х1 и любая размерность\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        # Нужно для следующего шага пока не запутываемся :) просто присвоили наш эмбеддинг\n",
    "        output = embedded\n",
    "        # и соответственно подаем все в GRU ячейку (эмбеддинг и скрытые состояния)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # Дополнительно сделаем инициализацию скрытого представления (просто заполним нулями)\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwLTlgSyM9uK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Построим  Decoder\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFbuUL1LM9uL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    # Будьте внимательны, теперь на вход мы получаем размер скрытого представления\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Создадим вспомогательные функции для работы с полученной репрезентацией и для кодирования для подачи в модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6gGPtXFM9uQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Токены кодируем в целочисленное представление\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "# Берем предложение с указанным языком, делаем из него индексы и вставляем метку конца предложения, превращаем в тензор:\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "# Для создания тензора из пар:\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Создадим функцию обучения для работы только с ОДНОЙ парой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fn8VDv8M9uS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Просто инициализируем скрытое представление для энкодера\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    # Скиыдваем градиенты для алгоритма градиентного спуска как и у энкодера так и у дэкодера\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Получаем размер в словаря (токенов) для входящего и выходящего тензора так как мы пробегаемся по каждому предложению по кусочкам\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    # Создаем переменную где будем хранить наши выходы из энкодера (в данной реализации пока не юзаем, далее будет еще один вариант)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    loss = 0\n",
    "    # пробегаем по длине входящего тензора и в экодер передаем последовательно каждый из токенов:\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        # Сохраняем все выходы из энкодера для одного слова (для передачи в декодер, ниже)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "\n",
    "    # Закончили с энкодером пошли к декодеру, как было сказано декодер начинается с SOS\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    # FYI здесь мы скрытое представление из энкодера передаем в скрытое представление в декодер, то есть после знака =\n",
    "    # у нас будут ходить градиенты из декодера в энкодер, то есть когда мы будем считать градиенты, они сначала пробегут по декодеру\n",
    "    # дойдут до знака = перескочат в энкодер и будут дальше считаться по энкодеру и эти градиенты сохранятся в соответствующих тензорах\n",
    "    # и когда будут отрабатывать разные оптимайзеры (у нас их 2) у них будут соответствующие правильные градиенты которые смогут правильно отработать\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Будем использовать Teacher Forcing в части случае (подставляя правильную последовательность)\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        # Подаем decoder_input = torch.tensor([[SOS_token]], device=device) то есть по одному слову и скрытое представление\n",
    "        for di in range(target_length):\n",
    "            # Переведенное предложение и скрытое представление\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Считаем ошибку\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Просто красивые функции для засекания времени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKsdwPmSM9uU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / percent\n",
    "    rs = es - s\n",
    "    return '%s (- eta: %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. Функция которая будет пробегаться по всем парам и использовать эти пары для обучения сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_z_k5IiM9uX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    # Делаем выборку наших пар функцией которую создали до\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    # FYI! Используем Negative Log-Likelihood Loss потому что log softmax уже присутствует в модели\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[epoch - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        # Используем функцию для тренировки на отдельных токенах, которую написали выше\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_iters),\n",
    "                                         epoch, epoch / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JXG-RzCM9uZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. Теперь построим функцию которая позволит нам использовать Encoder-Decoder для перевода предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Bxf45h6M9ud",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_sentences(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qUmQIGwM9uf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "references, predictions = [],[]\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        references.append(pair[1])\n",
    "        output_words, attentions = evaluate_sentences(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        predictions.append(output_sentence)\n",
    "        print('')\n",
    "\n",
    "    results = bleu.compute(predictions=predictions, references=references)\n",
    "    return f\"BLEU Score: {results}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 9. Этап обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "s_56t10oM9uh",
    "outputId": "f456b0b8-fc35-4199-fb19-b45c2330bf72",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 11s (- eta: 295m 38s) (5000 3%) 2.9374\n",
      "20m 13s (- eta: 283m 11s) (10000 6%) 2.3649\n",
      "30m 20s (- eta: 273m 2s) (15000 10%) 2.0127\n",
      "40m 23s (- eta: 262m 34s) (20000 13%) 1.7487\n",
      "50m 31s (- eta: 252m 37s) (25000 16%) 1.5956\n",
      "60m 42s (- eta: 242m 48s) (30000 20%) 1.4292\n",
      "70m 50s (- eta: 232m 45s) (35000 23%) 1.3545\n",
      "80m 59s (- eta: 222m 42s) (40000 26%) 1.2284\n",
      "91m 10s (- eta: 212m 43s) (45000 30%) 1.1175\n",
      "101m 18s (- eta: 202m 37s) (50000 33%) 1.0718\n",
      "111m 32s (- eta: 192m 40s) (55000 36%) 0.9762\n",
      "121m 47s (- eta: 182m 40s) (60000 40%) 0.9365\n",
      "131m 58s (- eta: 172m 34s) (65000 43%) 0.8720\n",
      "143m 24s (- eta: 163m 53s) (70000 46%) 0.8345\n",
      "155m 23s (- eta: 155m 23s) (75000 50%) 0.8029\n",
      "167m 38s (- eta: 146m 41s) (80000 53%) 0.7708\n",
      "180m 56s (- eta: 138m 22s) (85000 56%) 0.6915\n",
      "193m 18s (- eta: 128m 52s) (90000 60%) 0.7161\n",
      "208m 18s (- eta: 120m 35s) (95000 63%) 0.6794\n",
      "220m 25s (- eta: 110m 12s) (100000 66%) 0.6432\n",
      "231m 28s (- eta: 99m 12s) (105000 70%) 0.6160\n",
      "241m 46s (- eta: 87m 54s) (110000 73%) 0.5883\n",
      "252m 5s (- eta: 76m 43s) (115000 76%) 0.5649\n",
      "262m 22s (- eta: 65m 35s) (120000 80%) 0.5488\n",
      "272m 37s (- eta: 54m 31s) (125000 83%) 0.5381\n",
      "282m 54s (- eta: 43m 31s) (130000 86%) 0.5541\n",
      "295m 42s (- eta: 32m 51s) (135000 90%) 0.5091\n",
      "308m 43s (- eta: 22m 3s) (140000 93%) 0.4896\n",
      "321m 3s (- eta: 11m 4s) (145000 96%) 0.4841\n",
      "333m 27s (- eta: 0m 0s) (150000 100%) 0.4783\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 1024\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = AttentionDecoder(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "trainIters(encoder1, decoder1, 150_000, print_every=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 10. А теперь все что мы сварганили протестим на работе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> я у себя в квартире .\n",
      "= i m in my apartment .\n",
      "< i m in my apartment . <EOS>\n",
      "\n",
      "> я немного пьян .\n",
      "= i m a bit drunk .\n",
      "< i m a bit drunk . <EOS>\n",
      "\n",
      "> я очень рад за тебя !\n",
      "= i m very happy for you .\n",
      "< i m very happy for you . <EOS>\n",
      "\n",
      "> вы ведь не замужем ?\n",
      "= you re not married are you ?\n",
      "< you re not married are you ? <EOS>\n",
      "\n",
      "> я привык делать это один .\n",
      "= i m used to doing that alone .\n",
      "< i m used to do it alone . <EOS>\n",
      "\n",
      "> мы не молодеем .\n",
      "= we re not getting any younger .\n",
      "< we re not getting any younger . <EOS>\n",
      "\n",
      "> вы же женаты ?\n",
      "= you re married aren t you ?\n",
      "< you re married aren t you ? <EOS>\n",
      "\n",
      "> он идеален во всем .\n",
      "= he s perfect at everything .\n",
      "< he is perfect at everything . <EOS>\n",
      "\n",
      "> я внезапно устала .\n",
      "= i m suddenly tired .\n",
      "< i m suddenly tired . <EOS>\n",
      "\n",
      "> уверена что он поехал в токио .\n",
      "= i m sure that he went to tokyo .\n",
      "< i m sure that he went to tokyo . <EOS>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"BLEU Score: {'bleu': 0.5640518888996136, 'precisions': [0.6632653061224489, 0.6022727272727273, 0.5384615384615384, 0.47058823529411764], 'brevity_penalty': 1.0, 'length_ratio': 1.4411764705882353, 'translation_length': 98, 'reference_length': 68}\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEoEylSyM9uj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> вы не туда идете .\n",
      "= you re going the wrong direction .\n",
      "< you re going going wrong direction . <EOS>\n",
      "\n",
      "> нам понадобится помощь .\n",
      "= we re going to need help .\n",
      "< we re going to need some help . <EOS>\n",
      "\n",
      "> я уверен что у тебя были благие намерения .\n",
      "= i m sure your intentions were good .\n",
      "< i m sure your intentions were good . <EOS>\n",
      "\n",
      "> я не сумасшедшая .\n",
      "= i m not crazy .\n",
      "< i m not crazy . <EOS>\n",
      "\n",
      "> я необъективна .\n",
      "= i m biased .\n",
      "< i m biased . <EOS>\n",
      "\n",
      "> ты очень мудрыи .\n",
      "= you re very wise .\n",
      "< you re very wise . <EOS>\n",
      "\n",
      "> тебе рано замуж .\n",
      "= you re too young to get married .\n",
      "< you re too young to get married . <EOS>\n",
      "\n",
      "> я пытаюсь перевести песню .\n",
      "= i m trying to translate a song .\n",
      "< i m trying to translate a song . <EOS>\n",
      "\n",
      "> я варю кофе .\n",
      "= i m making coffee .\n",
      "< i m making coffee . <EOS>\n",
      "\n",
      "> вы странныи .\n",
      "= you re odd .\n",
      "< you re strange . <EOS>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"BLEU Score: {'bleu': 0.5366675564185387, 'precisions': [0.6526315789473685, 0.5823529411764706, 0.5066666666666667, 0.4307692307692308], 'brevity_penalty': 1.0, 'length_ratio': 1.4728682170542635, 'translation_length': 190, 'reference_length': 129}\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "После некоторых экспериментов с данным ноутбуком(изменение размернорсти скрытого слоя, эксперименты с длинной выражения) пришёл к выводу что данная модель требует серьёзной дороботки, так как даже увеличение длинны фразы до 20 симолов серьёзно снижает точность, а использование всего корпуса на 150к итерациях заняло около 10 часов и ошибка была около 2.3, только используя фильтр как в лекции и указав максимальную длину 10 символов я смог добиться более менее сносного результата, и он далёк от идеального. Корпус текста был скачен с сайта www.manythings.org и, поскольку в нём содержалась рекламная информация, Датасет был обработан дополнительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Лекция 8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
